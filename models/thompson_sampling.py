import numpy as np
import pandas as pd
from collections import defaultdict
import matplotlib.pyplot as plt

class ThompsonSamplingEvaluator:
    """
    Thompson Samplingì„ ì‚¬ìš©í•œ ì¶”ì²œ ì‹œìŠ¤í…œ í‰ê°€
    
    Multi-Armed Bandit ë¬¸ì œë¡œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì„ í‰ê°€:
    - ê° ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ = í•˜ë‚˜ì˜ Arm
    - í´ë¦­/ì¢‹ì•„ìš” = Reward
    """
    
    def __init__(self, algorithms):
        """
        Args:
            algorithms: í‰ê°€í•  ì•Œê³ ë¦¬ì¦˜ ë¦¬ìŠ¤íŠ¸
                        ì˜ˆ: ['NCF', 'MF', 'Content-Based']
        """
        self.algorithms = algorithms
        self.n_algorithms = len(algorithms)
        
        # ê° ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸ (Beta ë¶„í¬ íŒŒë¼ë¯¸í„°)
        self.alpha = {alg: 1 for alg in algorithms}  # ì„±ê³µ íšŸìˆ˜ + 1
        self.beta = {alg: 1 for alg in algorithms}   # ì‹¤íŒ¨ íšŸìˆ˜ + 1
        
        # í†µê³„
        self.total_selections = {alg: 0 for alg in algorithms}
        self.total_rewards = {alg: 0 for alg in algorithms}
        self.cumulative_regret = []
        
    def select_algorithm(self):
        """
        Thompson Samplingìœ¼ë¡œ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
        
        Returns:
            ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜ ì´ë¦„
        """
        samples = {}
        
        for alg in self.algorithms:
            # Beta ë¶„í¬ì—ì„œ ìƒ˜í”Œë§
            samples[alg] = np.random.beta(self.alpha[alg], self.beta[alg])
        
        # ê°€ì¥ ë†’ì€ ìƒ˜í”Œ ê°’ì„ ê°€ì§„ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
        selected = max(samples, key=samples.get)
        return selected
    
    def update(self, algorithm, reward):
        """
        ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸
        
        Args:
            algorithm: ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜
            reward: ë³´ìƒ (1=ì„±ê³µ, 0=ì‹¤íŒ¨)
        """
        self.total_selections[algorithm] += 1
        
        if reward > 0:
            self.alpha[algorithm] += 1
            self.total_rewards[algorithm] += reward
        else:
            self.beta[algorithm] += 1
    
    def get_statistics(self):
        """í˜„ì¬ í†µê³„ ë°˜í™˜"""
        stats = {}
        
        for alg in self.algorithms:
            total = self.total_selections[alg]
            if total > 0:
                ctr = self.total_rewards[alg] / total
                confidence = self.alpha[alg] / (self.alpha[alg] + self.beta[alg])
            else:
                ctr = 0
                confidence = 0.5
            
            stats[alg] = {
                'selections': total,
                'rewards': self.total_rewards[alg],
                'ctr': ctr,
                'confidence': confidence,
                'alpha': self.alpha[alg],
                'beta': self.beta[alg]
            }
        
        return stats
    
    def plot_results(self, save_path=None):
        """ê²°ê³¼ ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # 1. ì•Œê³ ë¦¬ì¦˜ë³„ ì„ íƒ íšŸìˆ˜
        ax1 = axes[0, 0]
        selections = [self.total_selections[alg] for alg in self.algorithms]
        ax1.bar(self.algorithms, selections, color='skyblue')
        ax1.set_title('Algorithm Selection Count')
        ax1.set_xlabel('Algorithm')
        ax1.set_ylabel('Selections')
        
        # 2. ì•Œê³ ë¦¬ì¦˜ë³„ CTR (Click-Through Rate)
        ax2 = axes[0, 1]
        ctrs = []
        for alg in self.algorithms:
            total = self.total_selections[alg]
            ctr = self.total_rewards[alg] / total if total > 0 else 0
            ctrs.append(ctr * 100)
        ax2.bar(self.algorithms, ctrs, color='lightgreen')
        ax2.set_title('Click-Through Rate (CTR)')
        ax2.set_xlabel('Algorithm')
        ax2.set_ylabel('CTR (%)')
        
        # 3. Beta ë¶„í¬ ì‹œê°í™”
        ax3 = axes[1, 0]
        x = np.linspace(0, 1, 100)
        for alg in self.algorithms:
            from scipy.stats import beta as beta_dist
            y = beta_dist.pdf(x, self.alpha[alg], self.beta[alg])
            ax3.plot(x, y, label=alg, linewidth=2)
        ax3.set_title('Posterior Distributions (Beta)')
        ax3.set_xlabel('Success Probability')
        ax3.set_ylabel('Density')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ì‹ ë¢°ë„ ì ìˆ˜
        ax4 = axes[1, 1]
        confidences = []
        for alg in self.algorithms:
            conf = self.alpha[alg] / (self.alpha[alg] + self.beta[alg])
            confidences.append(conf * 100)
        ax4.bar(self.algorithms, confidences, color='coral')
        ax4.set_title('Confidence Score')
        ax4.set_xlabel('Algorithm')
        ax4.set_ylabel('Confidence (%)')
        ax4.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='Random')
        ax4.legend()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥: {save_path}")
        
        plt.show()


def simulate_online_evaluation(test_data, models_predictions, n_iterations=1000):
    """
    ì˜¨ë¼ì¸ í‰ê°€ ì‹œë®¬ë ˆì´ì…˜
    
    Args:
        test_data: í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„ (user_id, recipe_id, label)
        models_predictions: ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
                           {'NCF': predictions, 'MF': predictions, ...}
        n_iterations: ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µ íšŸìˆ˜
    """
    
    algorithms = list(models_predictions.keys())
    evaluator = ThompsonSamplingEvaluator(algorithms)
    
    print("ğŸ° Thompson Sampling ì˜¨ë¼ì¸ í‰ê°€ ì‹œì‘\n")
    print(f"ì•Œê³ ë¦¬ì¦˜: {algorithms}")
    print(f"ë°˜ë³µ íšŸìˆ˜: {n_iterations}\n")
    
    # ì‹œë®¬ë ˆì´ì…˜
    for i in range(n_iterations):
        # ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
        selected_alg = evaluator.select_algorithm()
        
        # ëœë¤ ì‚¬ìš©ì-ë ˆì‹œí”¼ ìŒ ì„ íƒ
        idx = np.random.randint(len(test_data))
        true_label = test_data.iloc[idx]['implicit_score']  # ì‹¤ì œ ë ˆì´ë¸”
        
        # ì„ íƒëœ ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ˆì¸¡
        prediction = models_predictions[selected_alg][idx]
        
        # ë³´ìƒ ê³„ì‚° (ì˜ˆì¸¡ì´ ë§ìœ¼ë©´ 1, í‹€ë¦¬ë©´ 0)
        # ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìê°€ í´ë¦­í–ˆëŠ”ì§€ ì—¬ë¶€
        reward = 1 if (prediction > 0.5 and true_label > 0) else 0
        
        # ì—…ë°ì´íŠ¸
        evaluator.update(selected_alg, reward)
        
        # ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥
        if (i + 1) % 200 == 0:
            stats = evaluator.get_statistics()
            print(f"\në°˜ë³µ {i+1}/{n_iterations}:")
            for alg, stat in stats.items():
                print(f"  {alg:15s}: "
                      f"ì„ íƒ {stat['selections']:4d}íšŒ, "
                      f"CTR {stat['ctr']*100:5.2f}%, "
                      f"ì‹ ë¢°ë„ {stat['confidence']*100:5.2f}%")
    
    # ìµœì¢… ê²°ê³¼
    print("\n" + "="*70)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print("="*70)
    
    stats = evaluator.get_statistics()
    results_df = pd.DataFrame(stats).T
    results_df = results_df.round(4)
    print(results_df)
    
    # ìŠ¹ì ê²°ì •
    best_alg = max(stats.keys(), key=lambda x: stats[x]['ctr'])
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜: {best_alg}")
    print(f"   CTR: {stats[best_alg]['ctr']*100:.2f}%")
    
    # ì‹œê°í™”
    evaluator.plot_results('thompson_sampling_results.png')
    
    return evaluator, stats


# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    np.random.seed(42)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    n_samples = 1000
    test_data = pd.DataFrame({
        'user_id': np.random.randint(0, 100, n_samples),
        'recipe_id': np.random.randint(0, 500, n_samples),
        'implicit_score': np.random.randint(0, 2, n_samples)
    })
    
    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ (ë”ë¯¸)
    # ì‹¤ì œë¡œëŠ” í•™ìŠµëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ì‚¬ìš©
    models_predictions = {
        'NCF': np.random.rand(n_samples) * 0.7 + 0.15,  # ë” ì¢‹ì€ ì„±ëŠ¥
        'MF': np.random.rand(n_samples) * 0.6 + 0.1,
        'Content-Based': np.random.rand(n_samples) * 0.5 + 0.05
    }
    
    # í‰ê°€ ì‹¤í–‰
    evaluator, stats = simulate_online_evaluation(
        test_data, 
        models_predictions, 
        n_iterations=1000
    )