import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
import pickle
import os
import sys

# NCF ëª¨ë¸ ì„í¬íŠ¸ (ìœ„ì—ì„œ ì‘ì„±í•œ ncf.py)
from models.ncf import NCF, NCFDataGenerator, build_ncf_model

class NCFTrainer:
    """NCF ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤"""
    
    def __init__(self, config):
        self.config = config
        self.model = None
        self.history = None
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ë ˆì‹œí”¼ ë°ì´í„°
        self.recipes_df = pd.read_csv(self.config['recipes_path'])
        
        # ìƒí˜¸ì‘ìš© ë°ì´í„°
        self.train_df = pd.read_csv(self.config['train_path'])
        self.test_df = pd.read_csv(self.config['test_path'])
        
        # ì‚¬ìš©ì ë° ë ˆì‹œí”¼ ID ë²”ìœ„ í™•ì¸
        self.num_users = max(
            self.train_df['user_id'].max(),
            self.test_df['user_id'].max()
        ) + 1
        
        self.num_recipes = len(self.recipes_df)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"  - ì‚¬ìš©ì ìˆ˜: {self.num_users:,}")
        print(f"  - ë ˆì‹œí”¼ ìˆ˜: {self.num_recipes:,}")
        print(f"  - Train ìƒí˜¸ì‘ìš©: {len(self.train_df):,}")
        print(f"  - Test ìƒí˜¸ì‘ìš©: {len(self.test_df):,}")
        
    def prepare_training_data(self):
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (Negative Sampling)"""
        print("\nğŸ² í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘ (Negative Sampling)...")
        
        # Train ë°ì´í„° ìƒì„±
        train_generator = NCFDataGenerator(
            self.train_df, 
            num_negatives=self.config['num_negatives']
        )
        self.train_user_ids, self.train_recipe_ids, self.train_labels = \
            train_generator.generate_training_data()
        
        # Test ë°ì´í„° ìƒì„±
        test_generator = NCFDataGenerator(
            self.test_df,
            num_negatives=self.config['num_negatives']
        )
        self.test_user_ids, self.test_recipe_ids, self.test_labels = \
            test_generator.generate_training_data()
        
        print(f"âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print(f"  - Train ìƒ˜í”Œ: {len(self.train_labels):,}ê°œ")
        print(f"  - Test ìƒ˜í”Œ: {len(self.test_labels):,}ê°œ")
        print(f"  - Positive ë¹„ìœ¨: {self.train_labels.mean()*100:.1f}%")
        
    def build_model(self):
        """ëª¨ë¸ ìƒì„±"""
        print(f"\nğŸ—ï¸  NCF ëª¨ë¸ ìƒì„± ì¤‘...")
        print(f"  - ëª¨ë¸ íƒ€ì…: {self.config['model_type']}")
        print(f"  - ì„ë² ë”© ì°¨ì›: {self.config['embedding_dim']}")
        print(f"  - MLP ë ˆì´ì–´: {self.config['mlp_layers']}")
        
        self.model = build_ncf_model(
            num_users=self.num_users,
            num_recipes=self.num_recipes,
            model_type=self.config['model_type'],
            embedding_dim=self.config['embedding_dim'],
            mlp_layers=self.config['mlp_layers']
        )
        
        print("âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
    def train(self):
        """ëª¨ë¸ í•™ìŠµ"""
        print(f"\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        # ì½œë°± ì„¤ì •
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=5,
                restore_best_weights=True,
                verbose=1
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=3,
                min_lr=1e-6,
                verbose=1
            ),
            keras.callbacks.ModelCheckpoint(
                filepath=self.config['model_save_path'],
                monitor='val_auc',
                mode='max',
                save_best_only=True,
                verbose=1
            )
        ]
        
        # í•™ìŠµ
        self.history = self.model.fit(
            [self.train_user_ids, self.train_recipe_ids],
            self.train_labels,
            batch_size=self.config['batch_size'],
            epochs=self.config['epochs'],
            validation_data=(
                [self.test_user_ids, self.test_recipe_ids],
                self.test_labels
            ),
            callbacks=callbacks,
            verbose=1
        )
        
        print("\nâœ… í•™ìŠµ ì™„ë£Œ!")
        
    def evaluate(self):
        """ëª¨ë¸ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
        
        results = self.model.evaluate(
            [self.test_user_ids, self.test_recipe_ids],
            self.test_labels,
            batch_size=self.config['batch_size'],
            verbose=0
        )
        
        print("\nìµœì¢… ì„±ëŠ¥:")
        for metric_name, value in zip(self.model.metrics_names, results):
            print(f"  - {metric_name}: {value:.4f}")
        
        return dict(zip(self.model.metrics_names, results))
    
    def save_embeddings(self):
        """ë ˆì‹œí”¼ ì„ë² ë”© ì €ì¥ (ì‹¤ì‹œê°„ ì¶”ì²œìš©)"""
        print("\nğŸ’¾ ë ˆì‹œí”¼ ì„ë² ë”© ì €ì¥ ì¤‘...")
        
        recipe_embeddings = self.model.get_recipe_embeddings()
        
        embedding_path = self.config['embedding_save_path']
        np.save(embedding_path, recipe_embeddings)
        
        print(f"âœ… ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {embedding_path}")
        print(f"  - Shape: {recipe_embeddings.shape}")
        
    def save_training_history(self):
        """í•™ìŠµ ì´ë ¥ ì €ì¥"""
        history_path = self.config['model_save_path'].replace('.h5', '_history.pkl')
        with open(history_path, 'wb') as f:
            pickle.dump(self.history.history, f)
        print(f"ğŸ“ í•™ìŠµ ì´ë ¥ ì €ì¥: {history_path}")


# ì„¤ì •
CONFIG = {
    # ë°ì´í„° ê²½ë¡œ
    'recipes_path': 'data/processed/recipes_processed.csv',
    'train_path': 'data/processed/interactions_train.csv',
    'test_path': 'data/processed/interactions_test.csv',
    
    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    'model_type': 'NeuMF',  # 'GMF', 'MLP', 'NeuMF'
    'embedding_dim': 64,
    'mlp_layers': [128, 64, 32, 16],
    'num_negatives': 4,  # Positive ìƒ˜í”Œë‹¹ Negative ìƒ˜í”Œ ìˆ˜
    
    # í•™ìŠµ ì„¤ì •
    'batch_size': 256,
    'epochs': 50,
    'learning_rate': 0.001,
    
    # ì €ì¥ ê²½ë¡œ
    'model_save_path': 'data/models/ncf_model.h5',
    'embedding_save_path': 'data/models/recipe_embeddings.npy'
}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*70)
    print("ğŸ¯ NCF (Neural Collaborative Filtering) ëª¨ë¸ í•™ìŠµ")
    print("="*70)
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('data/models', exist_ok=True)
    
    # í•™ìŠµ ì‹œì‘
    trainer = NCFTrainer(CONFIG)
    
    # 1. ë°ì´í„° ë¡œë“œ
    trainer.load_data()
    
    # 2. í•™ìŠµ ë°ì´í„° ìƒì„±
    trainer.prepare_training_data()
    
    # 3. ëª¨ë¸ ë¹Œë“œ
    trainer.build_model()
    
    # 4. í•™ìŠµ
    trainer.train()
    
    # 5. í‰ê°€
    results = trainer.evaluate()
    
    # 6. ì„ë² ë”© ì €ì¥
    trainer.save_embeddings()
    
    # 7. í•™ìŠµ ì´ë ¥ ì €ì¥
    trainer.save_training_history()
    
    print("\n" + "="*70)
    print("âœ… ëª¨ë“  ê³¼ì • ì™„ë£Œ!")
    print("="*70)
    
    return trainer, results


if __name__ == "__main__":
    trainer, results = main()